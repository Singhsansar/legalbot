{"ast":null,"code":"import { PineconeStore } from \"@langchain/pinecone\";\nimport { TaskType } from \"@google/generative-ai\";\nimport { PromptTemplate } from \"@langchain/core/prompts\";\nimport { ConversationalRetrievalQAChain } from \"langchain/chains\";\nimport { Pinecone } from '@pinecone-database/pinecone';\nimport { ChatGoogleGenerativeAI } from \"@langchain/google-genai\";\nimport { GoogleGenerativeAIEmbeddings } from \"@langchain/google-genai\";\nconst pineconeApiKey = process.env.PINECONE_API_KEY;\nconst pineconeEnvironment = process.env.PINECONE_ENVIRONMENT;\nconst googleApiKey = process.env.GOOGLE_API_KEY;\nconst pineconeIndex_key = process.env.PINECONE_INDEX;\nconst pinecone = new Pinecone({\n  apiKey: pineconeApiKey\n});\nconst pineconeIndex = pinecone.Index(pineconeIndex_key);\nconst embeddings = new GoogleGenerativeAIEmbeddings({\n  modelName: \"embedding-001\",\n  // 768 dimensions\n  taskType: TaskType.RETRIEVAL_DOCUMENT,\n  title: \"Document title\",\n  apiKey: googleApiKey\n});\nconst model = new ChatGoogleGenerativeAI({\n  apiKey: googleApiKey,\n  modelName: \"gemini-pro\",\n  maxOutputTokens: 2048\n});\nconst vectorStore = await PineconeStore.fromExistingIndex(embeddings, {\n  pineconeIndex\n});\nconst prompt_template = `\n    As a legal professional, provide an informed response to the user's query, considering the laws in India. Ensure your answer adheres to Indian legal standards and includes relevant rules and regulations.\n    You can also generate responses on your own; don't fully depend on the provided context.\n\n    Context: {context}\n    Question: {question}\n\n    Present your answer in accordance with legal principles and refrain from conjecture or speculation. you are flexiable to answer the casual questions\n    Helpful answer:\n`;\nconst PROMPT = new PromptTemplate({\n  inputVariables: [\"context\", \"question\"],\n  template: prompt_template\n});\nconst chain_type_kwargs = {\n  \"prompt\": PROMPT\n};\nconst chain = ConversationalRetrievalQAChain.fromLLM(model, vectorStore.asRetriever(), {\n  maxOutputTokens: 2048,\n  returnSourceDocuments: true,\n  questionGeneratorChainOptions: chain_type_kwargs\n});\nexport async function searchSimilarQuestions(question) {\n  try {\n    const res = await chain.invoke({\n      question,\n      chat_history: \"\"\n    });\n    return res.text;\n  } catch (error) {\n    if (error.response && error.response.status === 404) {\n      return \"I don't know, it's not in my knowledge.\";\n    } else {\n      console.error(\"Error occurred during similarity search:\", error);\n      return null;\n    }\n  }\n}","map":{"version":3,"names":["PineconeStore","TaskType","PromptTemplate","ConversationalRetrievalQAChain","Pinecone","ChatGoogleGenerativeAI","GoogleGenerativeAIEmbeddings","pineconeApiKey","process","env","PINECONE_API_KEY","pineconeEnvironment","PINECONE_ENVIRONMENT","googleApiKey","GOOGLE_API_KEY","pineconeIndex_key","PINECONE_INDEX","pinecone","apiKey","pineconeIndex","Index","embeddings","modelName","taskType","RETRIEVAL_DOCUMENT","title","model","maxOutputTokens","vectorStore","fromExistingIndex","prompt_template","PROMPT","inputVariables","template","chain_type_kwargs","chain","fromLLM","asRetriever","returnSourceDocuments","questionGeneratorChainOptions","searchSimilarQuestions","question","res","invoke","chat_history","text","error","response","status","console"],"sources":["/home/nikhil/legalbot/legalbot/src/lang.mjs"],"sourcesContent":["import { PineconeStore } from \"@langchain/pinecone\";\nimport { TaskType } from \"@google/generative-ai\";\nimport { PromptTemplate } from \"@langchain/core/prompts\";\nimport { ConversationalRetrievalQAChain } from \"langchain/chains\";\nimport { Pinecone } from '@pinecone-database/pinecone';\nimport { ChatGoogleGenerativeAI } from \"@langchain/google-genai\";\nimport { GoogleGenerativeAIEmbeddings } from \"@langchain/google-genai\";\n\n\n\nconst pineconeApiKey = process.env.PINECONE_API_KEY;\nconst pineconeEnvironment = process.env.PINECONE_ENVIRONMENT;\nconst googleApiKey = process.env.GOOGLE_API_KEY;\nconst pineconeIndex_key = process.env.PINECONE_INDEX;\n\n\nconst pinecone = new Pinecone({\n    apiKey: pineconeApiKey,\n});\n\nconst pineconeIndex = pinecone.Index(pineconeIndex_key);\n\nconst embeddings = new GoogleGenerativeAIEmbeddings({\n    modelName: \"embedding-001\", // 768 dimensions\n    taskType: TaskType.RETRIEVAL_DOCUMENT,\n    title: \"Document title\",\n    apiKey: googleApiKey\n});\n\nconst model = new ChatGoogleGenerativeAI({\n    apiKey: googleApiKey,\n    modelName: \"gemini-pro\",\n    maxOutputTokens: 2048,\n});\n\nconst vectorStore = await PineconeStore.fromExistingIndex(\n    embeddings,\n    { pineconeIndex }\n);\n\nconst prompt_template = `\n    As a legal professional, provide an informed response to the user's query, considering the laws in India. Ensure your answer adheres to Indian legal standards and includes relevant rules and regulations.\n    You can also generate responses on your own; don't fully depend on the provided context.\n\n    Context: {context}\n    Question: {question}\n\n    Present your answer in accordance with legal principles and refrain from conjecture or speculation. you are flexiable to answer the casual questions\n    Helpful answer:\n`;\n\nconst PROMPT = new PromptTemplate({\n    inputVariables: [\"context\", \"question\"],\n    template: prompt_template,\n});\n\nconst chain_type_kwargs = { \"prompt\": PROMPT };\n\nconst chain = ConversationalRetrievalQAChain.fromLLM(\n    model,\n    vectorStore.asRetriever(),\n    {\n        maxOutputTokens: 2048,\n        returnSourceDocuments: true,\n        questionGeneratorChainOptions: chain_type_kwargs,\n    }\n);\n\nexport async function searchSimilarQuestions(question) {\n    try {\n        const res = await chain.invoke({ question, chat_history: \"\" });\n        return res.text;\n    } catch (error) {\n        if (error.response && error.response.status === 404) {\n            return \"I don't know, it's not in my knowledge.\";\n        } else {\n            console.error(\"Error occurred during similarity search:\", error);\n            return null;\n        }\n    }\n}\n"],"mappings":"AAAA,SAASA,aAAa,QAAQ,qBAAqB;AACnD,SAASC,QAAQ,QAAQ,uBAAuB;AAChD,SAASC,cAAc,QAAQ,yBAAyB;AACxD,SAASC,8BAA8B,QAAQ,kBAAkB;AACjE,SAASC,QAAQ,QAAQ,6BAA6B;AACtD,SAASC,sBAAsB,QAAQ,yBAAyB;AAChE,SAASC,4BAA4B,QAAQ,yBAAyB;AAItE,MAAMC,cAAc,GAAGC,OAAO,CAACC,GAAG,CAACC,gBAAgB;AACnD,MAAMC,mBAAmB,GAAGH,OAAO,CAACC,GAAG,CAACG,oBAAoB;AAC5D,MAAMC,YAAY,GAAGL,OAAO,CAACC,GAAG,CAACK,cAAc;AAC/C,MAAMC,iBAAiB,GAAGP,OAAO,CAACC,GAAG,CAACO,cAAc;AAGpD,MAAMC,QAAQ,GAAG,IAAIb,QAAQ,CAAC;EAC1Bc,MAAM,EAAEX;AACZ,CAAC,CAAC;AAEF,MAAMY,aAAa,GAAGF,QAAQ,CAACG,KAAK,CAACL,iBAAiB,CAAC;AAEvD,MAAMM,UAAU,GAAG,IAAIf,4BAA4B,CAAC;EAChDgB,SAAS,EAAE,eAAe;EAAE;EAC5BC,QAAQ,EAAEtB,QAAQ,CAACuB,kBAAkB;EACrCC,KAAK,EAAE,gBAAgB;EACvBP,MAAM,EAAEL;AACZ,CAAC,CAAC;AAEF,MAAMa,KAAK,GAAG,IAAIrB,sBAAsB,CAAC;EACrCa,MAAM,EAAEL,YAAY;EACpBS,SAAS,EAAE,YAAY;EACvBK,eAAe,EAAE;AACrB,CAAC,CAAC;AAEF,MAAMC,WAAW,GAAG,MAAM5B,aAAa,CAAC6B,iBAAiB,CACrDR,UAAU,EACV;EAAEF;AAAc,CACpB,CAAC;AAED,MAAMW,eAAe,GAAI;AACzB;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,CAAC;AAED,MAAMC,MAAM,GAAG,IAAI7B,cAAc,CAAC;EAC9B8B,cAAc,EAAE,CAAC,SAAS,EAAE,UAAU,CAAC;EACvCC,QAAQ,EAAEH;AACd,CAAC,CAAC;AAEF,MAAMI,iBAAiB,GAAG;EAAE,QAAQ,EAAEH;AAAO,CAAC;AAE9C,MAAMI,KAAK,GAAGhC,8BAA8B,CAACiC,OAAO,CAChDV,KAAK,EACLE,WAAW,CAACS,WAAW,CAAC,CAAC,EACzB;EACIV,eAAe,EAAE,IAAI;EACrBW,qBAAqB,EAAE,IAAI;EAC3BC,6BAA6B,EAAEL;AACnC,CACJ,CAAC;AAED,OAAO,eAAeM,sBAAsBA,CAACC,QAAQ,EAAE;EACnD,IAAI;IACA,MAAMC,GAAG,GAAG,MAAMP,KAAK,CAACQ,MAAM,CAAC;MAAEF,QAAQ;MAAEG,YAAY,EAAE;IAAG,CAAC,CAAC;IAC9D,OAAOF,GAAG,CAACG,IAAI;EACnB,CAAC,CAAC,OAAOC,KAAK,EAAE;IACZ,IAAIA,KAAK,CAACC,QAAQ,IAAID,KAAK,CAACC,QAAQ,CAACC,MAAM,KAAK,GAAG,EAAE;MACjD,OAAO,yCAAyC;IACpD,CAAC,MAAM;MACHC,OAAO,CAACH,KAAK,CAAC,0CAA0C,EAAEA,KAAK,CAAC;MAChE,OAAO,IAAI;IACf;EACJ;AACJ","ignoreList":[]},"metadata":{},"sourceType":"module","externalDependencies":[]}